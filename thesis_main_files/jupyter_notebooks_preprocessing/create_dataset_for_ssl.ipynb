{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f5a3ce8-e114-4694-94a8-830291bad329",
   "metadata": {},
   "source": [
    "# Load & structure metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e53b04b-a2e1-4197-aa31-c8e16a49f9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded metadata.csv with shape: (136304, 13)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import os\n",
    "\n",
    "# --- Load Metadata CSV ---\n",
    "metadata_path = '/Users/abhishekgupte_macbookpro/PycharmProjects/project_combined_repo_clean/thesis_main_files/datasets/processed/csv_files/lav_df/metadata/metadata.csv'  # Adjust path as needed\n",
    "df = pd.read_csv(metadata_path)\n",
    "\n",
    "print(f\"✅ Loaded metadata.csv with shape: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29cac28-ff7e-46da-b4c0-3a0d699d9095",
   "metadata": {},
   "source": [
    "# Parse list columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9873e2f3-ae31-4d49-9116-f966f2dd9404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Parsed list-like columns: ['fake_periods', 'timestamps']\n"
     ]
    }
   ],
   "source": [
    "# --- Convert stringified lists into actual lists ---\n",
    "list_columns = ['fake_periods', 'timestamps']\n",
    "\n",
    "for col in list_columns:\n",
    "    df[col] = df[col].apply(ast.literal_eval)\n",
    "\n",
    "print(f\"✅ Parsed list-like columns: {list_columns}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eedcfdd-3dc6-4e42-a890-5c5279126189",
   "metadata": {},
   "source": [
    "# Ensure correct data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "068eaa41-d15e-47b8-bd7d-fccfe6b86040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Column types after conversion:\n",
      "modify_video    bool\n",
      "modify_audio    bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# --- Ensure boolean columns are proper booleans ---\n",
    "df['modify_video'] = df['modify_video'].astype(bool)\n",
    "df['modify_audio'] = df['modify_audio'].astype(bool)\n",
    "\n",
    "# --- Confirm Column Types ---\n",
    "print(\"✅ Column types after conversion:\")\n",
    "print(df.dtypes[['modify_video', 'modify_audio']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466ab0ef-8610-4954-9bf4-c1c358b264ae",
   "metadata": {},
   "source": [
    "# Created new labels and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6782c7e-a222-4f93-85a9-5ce5f9a9cb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary label for fake videos (1 = Fake, 0 = Real)\n",
    "df['label'] = df['n_fakes'].apply(lambda x: 1 if x >= 1 else 0)\n",
    "df['av_combo'] = df.apply(lambda row: f\"A{int(row['modify_audio'])}_V{int(row['modify_video'])}\", axis=1)\n",
    "df['fake_segment_count'] = df['fake_periods'].apply(lambda x: len(x) if x else 0)\n",
    "def compute_total_fake_length(fake_periods):\n",
    "    if not fake_periods:\n",
    "        return 0.0\n",
    "    return sum(end - start for start, end in fake_periods)\n",
    "\n",
    "df['total_fake_length'] = df['fake_periods'].apply(compute_total_fake_length)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b590c5-e9c0-42fc-9e23-43020a05286b",
   "metadata": {},
   "source": [
    "# Quick verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68dcbf1f-2c3e-4d91-8157-840f9464e7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         file  n_fakes  label av_combo  fake_segment_count  total_fake_length\n",
      "0  000001.mp4        0      0    A0_V0                   0              0.000\n",
      "1  000000.mp4        0      0    A0_V0                   0              0.000\n",
      "2  000002.mp4        1      1    A1_V1                   1              0.724\n",
      "3  000003.mp4        1      1    A0_V1                   1              0.280\n",
      "4  000004.mp4        1      1    A1_V0                   1              0.704\n"
     ]
    }
   ],
   "source": [
    "print(df[['file', 'n_fakes', 'label', 'av_combo', 'fake_segment_count', 'total_fake_length']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd223457-5a34-447c-9e3a-6224ca8f36d6",
   "metadata": {},
   "source": [
    "# Save 70% of REAL sampled videos for training SSL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be904f86-9725-46c6-929b-ebe8747459f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved sampled real videos (70% of 36431) to /Users/abhishekgupte_macbookpro/PycharmProjects/project_combined_repo_clean_preprocessing/files/csv_files/processed/video/possible_training_sample.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Parameters ---\n",
    "output_sampled_path = '/Users/abhishekgupte_macbookpro/PycharmProjects/project_combined_repo_clean_preprocessing/files/csv_files/processed/video/possible_training_sample.csv'  # Adjust as needed\n",
    "\n",
    "# --- Filter Real Videos ---\n",
    "df_real = df[df['label'] == 0]\n",
    "\n",
    "# --- Sample 70% Randomly ---\n",
    "df_real_sampled = df_real.sample(frac=0.7, random_state=42)\n",
    "\n",
    "# --- Save to CSV ---\n",
    "os.makedirs(os.path.dirname(output_sampled_path), exist_ok=True)\n",
    "df_real_sampled.to_csv(output_sampled_path, index=False)\n",
    "\n",
    "print(f\"✅ Saved sampled real videos (70% of {len(df_real)}) to {output_sampled_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39db0f20-7c91-4b1b-b8de-7a76efb7e882",
   "metadata": {},
   "source": [
    "# Save 70% of REAL sampled videos for training SSL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b1b67cc-562a-4f92-b7fb-c8705607db33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved first 50% to: /Users/abhishekgupte_macbookpro/PycharmProjects/project_combined_repo_clean_preprocessing/files/csv_files/processed/video/sample_real_70_percent_half1.csv (12751 rows)\n",
      "✅ Saved second 50% to: /Users/abhishekgupte_macbookpro/PycharmProjects/project_combined_repo_clean_preprocessing/files/csv_files/processed/video/sample_real_70_percent_half2.csv (12751 rows)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "imput_sampled_data = '/Users/abhishekgupte_macbookpro/PycharmProjects/project_combined_repo_clean_preprocessing/files/csv_files/processed/video/possible_training_sample.csv'  # Adjust as needed\n",
    "\n",
    "df_real_sampled = pd.read_csv(imput_sampled_data)\n",
    "\n",
    "\n",
    "# --- File paths for the two halves ---\n",
    "half_1_path = '/Users/abhishekgupte_macbookpro/PycharmProjects/project_combined_repo_clean_preprocessing/files/csv_files/processed/video/sample_real_70_percent_half1.csv'\n",
    "half_2_path = '/Users/abhishekgupte_macbookpro/PycharmProjects/project_combined_repo_clean_preprocessing/files/csv_files/processed/video/sample_real_70_percent_half2.csv'\n",
    "\n",
    "# --- Calculate 50% of the sampled set ---\n",
    "half_sample_size = len(df_real_sampled) // 2\n",
    "\n",
    "# --- Shuffle & Split ---\n",
    "df_real_sampled_shuffled = df_real_sampled.sample(frac=1.0, random_state=123).reset_index(drop=True)\n",
    "df_half1 = df_real_sampled_shuffled.iloc[:half_sample_size]\n",
    "df_half2 = df_real_sampled_shuffled.iloc[half_sample_size:]\n",
    "\n",
    "# --- Save to CSVs ---\n",
    "df_half1.to_csv(half_1_path, index=False)\n",
    "df_half2.to_csv(half_2_path, index=False)\n",
    "\n",
    "print(f\"✅ Saved first 50% to: {half_1_path} ({len(df_half1)} rows)\")\n",
    "print(f\"✅ Saved second 50% to: {half_2_path} ({len(df_half2)} rows)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11bc811-fa7b-422c-a016-310cb7e267f4",
   "metadata": {},
   "source": [
    "# Save 30% hold-out set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51a6f8d8-d54d-4921-ab07-c60f51a32d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Path for holdout set ---\n",
    "holdout_path = 'data/holdout_30_percent_for_training.csv'\n",
    "\n",
    "# --- Ensure file column exists and is unique in df_real ---\n",
    "assert df_real['file'].is_unique, \"The 'file' column should be unique for this operation.\"\n",
    "\n",
    "# --- Get 30% holdout set using 'file' to exclude sampled videos ---\n",
    "df_real_holdout = df_real[~df_real['file'].isin(df_real_sampled['file'])]\n",
    "\n",
    "# --- Sanity check ---\n",
    "assert len(df_real_holdout) + len(df_real_sampled) == len(df_real), \"Mismatch in split sizes!\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a15854-5b9e-463f-a26f-07c1d68ff665",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
